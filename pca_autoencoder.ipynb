{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shape_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0105bd36df58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmesh_sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrimesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mshape_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoencoder_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_autoencoder_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shape_data'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import mesh_sampling\n",
    "import trimesh\n",
    "from shape_data import ShapeData\n",
    "\n",
    "from autoencoder_dataset import cached_autoencoder_dataset, autoencoder_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from spiral_utils import get_adj_trigs, generate_spirals\n",
    "from train_funcs import train_autoencoder_dataloader\n",
    "from test_funcs import test_autoencoder_dataloader\n",
    "\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "meshpackage = 'trimesh' # 'mpi-mesh', 'trimesh'\n",
    "root_dir = '/home/jingwang/Data/data/'\n",
    "\n",
    "dataset = 'FaceWarehouse'\n",
    "name = 'neutral'\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "GPU = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"3\"\n",
    "device_idx = 0\n",
    "print(torch.cuda.get_device_name(device_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "generative_model = 'pca_autoencoder'\n",
    "\n",
    "reference_mesh_file = os.path.join(root_dir, dataset, 'template', 'template.obj')\n",
    "\n",
    "args = {'generative_model': generative_model,\n",
    "        'name': name, 'data': os.path.join(root_dir, dataset, 'preprocessed',name),\n",
    "        'results_folder':  os.path.join(root_dir, dataset,'results/fully_connected_'+ generative_model),\n",
    "        'checkpoint_file': 'checkpoint',\n",
    "        'seed':2, 'loss':'l1',\n",
    "        'batch_size': 8, 'num_epochs':3000, 'eval_frequency':200, 'num_workers': 40,\n",
    "        'nz': 16,\n",
    "        \n",
    "        'lr':1e-3, \n",
    "        'regularization': 5e-5,         \n",
    "        'scheduler': True, 'decay_rate': 0.99,'decay_steps':1,  \n",
    "        'resume': False,\n",
    "        'reference_mesh_file': reference_mesh_file,\n",
    "        'mode':'test', 'shuffle': False, 'nVal': 100, 'normalization': True,\n",
    "        'write_mesh': True,\n",
    "        'lambda_var': 0.5,\n",
    "        'worst_face_num': 20}\n",
    "\n",
    "args['results_folder'] = os.path.join(args['results_folder'],'latent_'+str(args['nz']))\n",
    "    \n",
    "if not os.path.exists(os.path.join(args['results_folder'])):\n",
    "    os.makedirs(os.path.join(args['results_folder']))\n",
    "\n",
    "summary_path = os.path.join(args['results_folder'],'summaries',args['name'])\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)  \n",
    "    \n",
    "checkpoint_path = os.path.join(args['results_folder'],'checkpoints', args['name'])\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "samples_path = os.path.join(args['results_folder'],'samples', args['name'])\n",
    "if not os.path.exists(samples_path):\n",
    "    os.makedirs(samples_path)\n",
    "    \n",
    "prediction_path = os.path.join(args['results_folder'],'predictions', args['name'])\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.makedirs(prediction_path)\n",
    "\n",
    "downsample_mesh_path = os.path.join(args['results_folder'],'downsample_mesh', args['name'])\n",
    "if not os.path.exists(downsample_mesh_path):\n",
    "    os.makedirs(downsample_mesh_path)\n",
    "\n",
    "\n",
    "worst_mesh_path = os.path.join(args['results_folder'],'worst_test', args['name'])\n",
    "if not os.path.exists(downsample_mesh_path):\n",
    "    os.makedirs(downsample_mesh_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "specified material ()  not loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data .. \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(args['seed'])\n",
    "print(\"Loading data .. \")\n",
    "if not os.path.exists(args['data']+'/mean.npy') or not os.path.exists(args['data']+'/std.npy'):\n",
    "    shapedata =  ShapeData(nVal=args['nVal'], \n",
    "                          train_file=args['data']+'/train.npy', \n",
    "                          test_file=args['data']+'/test.npy', \n",
    "                          reference_mesh_file=args['reference_mesh_file'],\n",
    "                          normalization = args['normalization'],\n",
    "                          meshpackage = meshpackage, load_flag = True)\n",
    "    np.save(args['data']+'/mean.npy', shapedata.mean)\n",
    "    np.save(args['data']+'/std.npy', shapedata.std)\n",
    "else:\n",
    "    shapedata = ShapeData(nVal=args['nVal'], \n",
    "                         train_file=args['data']+'/train.npy',\n",
    "                         test_file=args['data']+'/test.npy', \n",
    "                         reference_mesh_file=args['reference_mesh_file'],\n",
    "                         normalization = args['normalization'],\n",
    "                         meshpackage = meshpackage, load_flag = False)\n",
    "    shapedata.mean = np.load(args['data']+'/mean.npy')\n",
    "    shapedata.std = np.load(args['data']+'/std.npy')\n",
    "    shapedata.n_vertex = shapedata.mean.shape[0]\n",
    "    shapedata.n_features = shapedata.mean.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "if GPU:\n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Building model, optimizer, and loss function\n",
    "\n",
    "dataset_train = cached_autoencoder_dataset(root_dir = args['data'], points_dataset = 'train',\n",
    "                                           shapedata = shapedata,\n",
    "                                           normalization = args['normalization'],device=device)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = args['shuffle'])\n",
    "\n",
    "dataset_val = cached_autoencoder_dataset(root_dir = args['data'], points_dataset = 'val', \n",
    "                                         shapedata = shapedata,\n",
    "                                         normalization = args['normalization'],device=device)\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = False)\n",
    "\n",
    "\n",
    "dataset_test = autoencoder_dataset(root_dir = args['data'], points_dataset = 'test',\n",
    "                                          shapedata = shapedata,\n",
    "                                          normalization = args['normalization'])\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = False, num_workers = args['num_workers'],  pin_memory=True)\n",
    "\n",
    "if 'pca_autoencoder' == args['generative_model']:\n",
    "    import torch.nn as nn\n",
    "    class PcaAutoEncoder(nn.Module):\n",
    "        def __init__(self, nz):\n",
    "            super().__init__()\n",
    "            self.nz = nz\n",
    "            self.en_fc = nn.Linear(11511*3, nz)\n",
    "            self.de_fc = nn.Linear(nz, 11511*3)\n",
    "            self._only_encode = False\n",
    "            self._only_decode = False\n",
    "        \n",
    "        def only_encode(self, status):\n",
    "            self._only_encode = status\n",
    "        \n",
    "        def only_decode(self, status):\n",
    "            self._only_decode = status\n",
    "        \n",
    "        def encode(self, x):\n",
    "            z = self.en_fc(x)\n",
    "            return z\n",
    "        \n",
    "        def decode(self, z):\n",
    "            x = self.de_fc(z)\n",
    "            return x\n",
    "        \n",
    "        def forward(self, x):\n",
    "            if self._only_decode:\n",
    "                x = self.decode(x)\n",
    "                x = x.reshape(x.shape[0], -1, 3)\n",
    "                return x\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            z = self.encode(x)\n",
    "            if self._only_encode:\n",
    "                return z\n",
    "            x = self.decode(z)\n",
    "            x = x.reshape(x.shape[0], -1, 3)\n",
    "            return x\n",
    "        \n",
    "    model = PcaAutoEncoder(nz=args['nz']).to(device)\n",
    "    \n",
    "optim = torch.optim.Adam(model.parameters(),lr=args['lr'],weight_decay=args['regularization'])\n",
    "if args['scheduler']:\n",
    "    scheduler=torch.optim.lr_scheduler.StepLR(optim, args['decay_steps'],gamma=args['decay_rate'])\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "def loss_l2(outputs, targets):\n",
    "    L = torch.sqrt(torch.mean((outputs - targets)**2))\n",
    "    return L\n",
    "    \n",
    "if args['loss']=='l1':\n",
    "    def loss_l1(outputs, targets):\n",
    "        L = torch.abs(outputs - targets).mean()\n",
    "        return L \n",
    "    loss_fn = loss_l1\n",
    "elif arg['loss']=='l1_var':\n",
    "    lambda_var = args['lambda_var']\n",
    "    def variational_loss(tx,tx_hat):\n",
    "        x,mu,logvar = tx\n",
    "        l1_loss = torch.mean(torch.abs(x-tx))\n",
    "        var_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return l1_loss + lambda_var * var_loss\n",
    "    loss_fn = variational_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 1139605\n",
      "PcaAutoEncoder(\n",
      "  (en_fc): Linear(in_features=34533, out_features=16, bias=True)\n",
      "  (de_fc): Linear(in_features=16, out_features=34533, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params)) \n",
    "print(model)\n",
    "# print(M[4].v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args['mode'] == 'train':\n",
    "    writer = SummaryWriter(summary_path)\n",
    "    with open(os.path.join(args['results_folder'],'checkpoints', args['name'] +'_params.json'),'w') as fp:\n",
    "        saveparams = copy.deepcopy(args)\n",
    "        json.dump(saveparams, fp)\n",
    "        \n",
    "    if args['resume']:\n",
    "            print('loading checkpoint from file %s'%(os.path.join(checkpoint_path,args['checkpoint_file'])))\n",
    "            checkpoint_dict = torch.load(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar'),map_location=device)\n",
    "            start_epoch = checkpoint_dict['epoch'] + 1\n",
    "            model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "            optim.load_state_dict(checkpoint_dict['optimizer_state_dict'])\n",
    "            scheduler.load_state_dict(checkpoint_dict['scheduler_state_dict'])\n",
    "            print('Resuming from epoch %s'%(str(start_epoch)))     \n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        \n",
    "    if args['generative_model'] in ['autoencoder', 'simple_autoencoder', 'pca_autoencoder']:\n",
    "        train_autoencoder_dataloader(dataloader_train, dataloader_val,\n",
    "                          device, model, optim, loss_fn,\n",
    "                          bsize = args['batch_size'],\n",
    "                          start_epoch = start_epoch,\n",
    "                          n_epochs = args['num_epochs'],\n",
    "                          eval_freq = args['eval_frequency'],\n",
    "                          scheduler = scheduler,\n",
    "                          writer = writer,\n",
    "                          save_recons=True,\n",
    "                          shapedata=shapedata,\n",
    "                          metadata_dir=checkpoint_path, samples_dir=samples_path,\n",
    "                          checkpoint_path = args['checkpoint_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint from file /home/jingwang/Data/data/FaceWarehouse/results/spirals_simple_autoencoder/latent_128/checkpoints/align_pose/checkpoint.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:02<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss for ', 612, tensor(4.3394, device='cuda:0'))\n",
      "('loss for ', 602, tensor(4.3528, device='cuda:0'))\n",
      "('loss for ', 194, tensor(4.3574, device='cuda:0'))\n",
      "('loss for ', 560, tensor(4.3619, device='cuda:0'))\n",
      "('loss for ', 390, tensor(4.4021, device='cuda:0'))\n",
      "('loss for ', 402, tensor(4.3611, device='cuda:0'))\n",
      "('loss for ', 537, tensor(4.4436, device='cuda:0'))\n",
      "('loss for ', 625, tensor(4.3799, device='cuda:0'))\n",
      "('loss for ', 8, tensor(4.4154, device='cuda:0'))\n",
      "('loss for ', 628, tensor(4.5263, device='cuda:0'))\n",
      "('loss for ', 559, tensor(4.6070, device='cuda:0'))\n",
      "('loss for ', 626, tensor(4.6145, device='cuda:0'))\n",
      "('loss for ', 370, tensor(4.4514, device='cuda:0'))\n",
      "('loss for ', 125, tensor(4.5456, device='cuda:0'))\n",
      "('loss for ', 389, tensor(4.4977, device='cuda:0'))\n",
      "('loss for ', 364, tensor(4.5176, device='cuda:0'))\n",
      "('loss for ', 169, tensor(4.5499, device='cuda:0'))\n",
      "('loss for ', 499, tensor(4.4825, device='cuda:0'))\n",
      "('loss for ', 341, tensor(4.4610, device='cuda:0'))\n",
      "('loss for ', 50, tensor(4.5558, device='cuda:0'))\n",
      "('autoencoder: normalized loss', 0.3011136054992676)\n",
      "('autoencoder: euclidean distance in mm=', 2.037527322769165)\n"
     ]
    }
   ],
   "source": [
    "if args['mode'] == 'test':\n",
    "    print('loading checkpoint from file %s'%(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar')))\n",
    "    checkpoint_dict = torch.load(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar'),map_location=device)\n",
    "    model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "        \n",
    "    predictions, norm_l1_loss, l2_loss = test_autoencoder_dataloader(device, model, dataloader_test, \n",
    "                                                                     shapedata, worst_path=worst_mesh_path, \n",
    "                                                                     worst_face_num=args['worst_face_num'],\n",
    "                                                                     mm_constant = 100)    \n",
    "    np.save(os.path.join(prediction_path,'predictions'), predictions)   \n",
    "        \n",
    "    print('autoencoder: normalized loss', norm_l1_loss)\n",
    "    \n",
    "    print('autoencoder: euclidean distance in mm=', l2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint from file /home/jingwang/Data/data/FaceWarehouse/results/fully_connected_simple_autoencoder/latent_128/checkpoints/align_pose/checkpoint.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [00:18<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss for ', 4407, tensor(0.7333, device='cuda:0'))\n",
      "('loss for ', 7990, tensor(0.7386, device='cuda:0'))\n",
      "('loss for ', 4652, tensor(0.7499, device='cuda:0'))\n",
      "('loss for ', 4229, tensor(0.7571, device='cuda:0'))\n",
      "('loss for ', 9272, tensor(0.8053, device='cuda:0'))\n",
      "('loss for ', 5009, tensor(0.7569, device='cuda:0'))\n",
      "('loss for ', 5751, tensor(0.7895, device='cuda:0'))\n",
      "('loss for ', 3968, tensor(0.7604, device='cuda:0'))\n",
      "('loss for ', 8612, tensor(0.7764, device='cuda:0'))\n",
      "('loss for ', 4689, tensor(0.8434, device='cuda:0'))\n",
      "('loss for ', 2876, tensor(0.8575, device='cuda:0'))\n",
      "('loss for ', 8032, tensor(0.7779, device='cuda:0'))\n",
      "('loss for ', 2945, tensor(0.7627, device='cuda:0'))\n",
      "('loss for ', 6959, tensor(0.8138, device='cuda:0'))\n",
      "('loss for ', 1443, tensor(0.9869, device='cuda:0'))\n",
      "('loss for ', 988, tensor(0.8157, device='cuda:0'))\n",
      "('loss for ', 2040, tensor(0.8673, device='cuda:0'))\n",
      "('loss for ', 2952, tensor(0.7869, device='cuda:0'))\n",
      "('loss for ', 8520, tensor(0.8912, device='cuda:0'))\n",
      "('loss for ', 4046, tensor(0.8836, device='cuda:0'))\n",
      "('autoencoder: normalized loss', 0.027093905955553055)\n",
      "('autoencoder: euclidean distance in mm=', 0.2252335399389267)\n"
     ]
    }
   ],
   "source": [
    "if args['mode'] == 'test': # test with train set\n",
    "    print('loading checkpoint from file %s'%(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar')))\n",
    "    checkpoint_dict = torch.load(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar'),map_location=device)\n",
    "    model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "        \n",
    "    predictions, norm_l1_loss, l2_loss = test_autoencoder_dataloader(device, model, dataloader_train, \n",
    "                                                                     shapedata, worst_path=worst_mesh_path, \n",
    "                                                                     worst_face_num=args['worst_face_num'],\n",
    "                                                                     mm_constant = 100)    \n",
    "    np.save(os.path.join(prediction_path,'predictions'), predictions)   \n",
    "        \n",
    "    print('autoencoder: normalized loss', norm_l1_loss)\n",
    "    \n",
    "    print('autoencoder: euclidean distance in mm=', l2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 186.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint from file /home/jingwang/Data/data/FaceWarehouse/results/fully_connected_pca_autoencoder/latent_16/checkpoints/neutral/checkpoint.pth.tar\n",
      "loss for  7 tensor(1.1442, device='cuda:0')\n",
      "loss for  5 tensor(1.4197, device='cuda:0')\n",
      "loss for  0 tensor(1.4422, device='cuda:0')\n",
      "loss for  2 tensor(1.5218, device='cuda:0')\n",
      "loss for  3 tensor(1.6134, device='cuda:0')\n",
      "loss for  2 tensor(1.7671, device='cuda:0')\n",
      "loss for  6 tensor(1.6526, device='cuda:0')\n",
      "loss for  1 tensor(1.6962, device='cuda:0')\n",
      "loss for  3 tensor(1.6305, device='cuda:0')\n",
      "loss for  4 tensor(1.6477, device='cuda:0')\n",
      "autoencoder: normalized loss 0.24331627786159515\n",
      "autoencoder: euclidean distance in mm= 1.5535428524017334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if args['mode'] == 'test': # test with val set\n",
    "    print('loading checkpoint from file %s'%(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar')))\n",
    "    checkpoint_dict = torch.load(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar'),map_location=device)\n",
    "    model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "        \n",
    "    predictions, norm_l1_loss, l2_loss = test_autoencoder_dataloader(device, model, dataloader_val, \n",
    "                                                                     shapedata, worst_path=worst_mesh_path, \n",
    "                                                                     worst_face_num=args['worst_face_num'],\n",
    "                                                                     mm_constant = 100)    \n",
    "    np.save(os.path.join(prediction_path,'predictions'), predictions)   \n",
    "        \n",
    "    print('autoencoder: normalized loss', norm_l1_loss)\n",
    "    \n",
    "    print('autoencoder: euclidean distance in mm=', l2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11511, 3])\n",
      "loss  0.24329513311386108\n",
      "loss  0.24329493939876556\n",
      "loss  0.24329471588134766\n",
      "loss  0.24329450726509094\n",
      "loss  0.24329429864883423\n",
      "loss  0.2432941049337387\n",
      "loss  0.2432938665151596\n",
      "loss  0.24329368770122528\n",
      "loss  0.24329344928264618\n",
      "loss  0.24329324066638947\n",
      "loss  0.24329303205013275\n",
      "loss  0.24329283833503723\n",
      "loss  0.24329259991645813\n",
      "loss  0.2432924211025238\n",
      "loss  0.2432921975851059\n",
      "loss  0.243291974067688\n",
      "loss  0.24329176545143127\n",
      "loss  0.24329157173633575\n",
      "loss  0.24329133331775665\n",
      "loss  0.24329115450382233\n",
      "tensor([[-2.1633e+01,  2.0553e+01,  4.9337e+01,  1.6851e+00,  2.3712e+01,\n",
      "         -3.7888e+01, -1.4641e+01, -3.7942e+01,  3.1905e+01, -2.4031e+01,\n",
      "          1.8875e+01, -3.5214e+01, -2.7131e+01,  3.2612e+01,  7.3559e+00,\n",
      "         -9.1403e-01],\n",
      "        [ 5.0887e+00, -4.2406e+00, -1.8859e+01,  4.0508e+01,  3.1154e+01,\n",
      "         -6.6240e+01, -2.3830e+01, -6.9777e+01,  4.2486e+01,  1.3714e+00,\n",
      "          3.7937e+01,  2.1957e+00,  4.2534e+01,  3.6115e+00, -3.7478e+01,\n",
      "         -2.5504e+01],\n",
      "        [-1.7244e+01,  2.0832e+01,  3.2837e+01, -1.8323e+01,  2.0134e+01,\n",
      "         -3.8102e+01, -4.1273e+01, -1.2494e+01, -1.3776e+01, -4.6756e+01,\n",
      "          4.8707e+01, -2.6016e+01, -1.9557e+01,  1.3521e+00, -6.5691e+01,\n",
      "         -2.0458e+01],\n",
      "        [ 1.0221e+00, -1.0165e+01, -4.2662e+01,  3.3774e+01,  1.1401e+01,\n",
      "         -1.1128e+01, -2.6130e+01, -3.5344e+01,  1.8386e+01, -3.0578e+01,\n",
      "          4.6449e+01, -2.2363e+01, -3.8228e+01,  4.4915e+01,  2.1171e+01,\n",
      "         -1.2557e+01],\n",
      "        [-6.1280e+00,  2.0549e+01,  1.0892e+02, -7.9975e+00, -1.6960e+01,\n",
      "          4.8530e+00,  1.6408e+01, -2.2470e+01, -3.5903e+01, -1.5252e+01,\n",
      "          1.6218e+01, -3.2623e+01,  4.2643e+01, -4.7392e+00,  8.7407e+00,\n",
      "         -3.9167e+00],\n",
      "        [-1.4564e+01, -4.0631e+01,  2.7039e+01,  7.1112e+00,  3.1661e+00,\n",
      "          1.7347e+01, -3.1734e+01,  1.0613e+01,  2.3263e+00, -2.3721e+01,\n",
      "          4.5096e+01, -2.3677e-03, -2.0243e+01, -1.2652e+01, -1.3315e+01,\n",
      "          2.8728e+01],\n",
      "        [-6.4686e+00,  9.7083e+00, -1.6120e+01, -2.2554e+01,  2.2722e+00,\n",
      "         -1.6716e+01, -5.5395e+00, -2.6768e+00,  1.8270e+01, -2.6112e+01,\n",
      "          4.0211e+01, -4.5079e+01, -2.1203e+01,  1.6972e+01,  3.0843e+01,\n",
      "          4.1973e-01],\n",
      "        [-2.7917e+01,  1.8597e+00,  2.3943e+01,  1.8998e+01, -1.7603e+01,\n",
      "         -3.2973e+01, -1.8601e+01, -6.1999e+01,  4.3164e+01,  1.0986e+01,\n",
      "          2.8515e+01, -2.6932e+01, -1.4099e+00, -1.3169e+01,  2.0511e+01,\n",
      "         -1.1494e+01],\n",
      "        [-9.9907e+00,  3.9465e+00, -1.3983e+01,  2.3855e+01, -1.2307e+01,\n",
      "         -6.2232e+01, -1.9366e+01,  2.2374e+01, -1.3836e+00, -3.0124e+01,\n",
      "          3.3598e+01,  7.4444e+00,  2.9435e+00,  1.5637e+00,  2.8579e+01,\n",
      "          1.9292e+00],\n",
      "        [-1.1549e+01, -2.8890e+01, -1.4880e+01, -6.4384e+00, -1.7252e+00,\n",
      "         -1.5236e+01, -1.3475e+01, -1.5763e+00,  2.1953e+01,  4.1802e-01,\n",
      "          5.3015e+01, -2.6517e+01, -5.0115e+00,  7.9838e+00,  2.1585e+01,\n",
      "         -1.7749e+00]], device='cuda:0')\n",
      "0 tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "1 tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "2 tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "3 tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "4 tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "5 tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "6 tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "7 tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "8 tensor(0.0152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "9 tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# from optimize_to_get_result import optimize_to_get_result\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def optimize_to_get_result(model, loss_fun, z_dim, device, targets, n_iter=1, output_loss=True):\n",
    "    model.eval()\n",
    "    \n",
    "#     return torch.empty(0), model(targets)\n",
    "    \n",
    "    model.only_encode(True)\n",
    "    z = model(targets)\n",
    "    model.only_encode(False)\n",
    "    \n",
    "    model.only_decode(True)\n",
    "    z_param = nn.Parameter(z)\n",
    "    optimizer = optim.LBFGS(params=[z_param])\n",
    "    for it in range(n_iter):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(z_param)\n",
    "            outputs = outputs.reshape(targets.shape) # decode, don't know shape\n",
    "            loss = loss_fun(outputs, targets)\n",
    "            loss.backward()\n",
    "            if output_loss:\n",
    "                print('loss ', loss.item())\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "    outputs = model(z_param)\n",
    "    outputs = outputs.reshape(targets.shape)\n",
    "    \n",
    "    model.only_decode(False)\n",
    "    return z_param.data, outputs\n",
    "\n",
    "def work_optimize():\n",
    "\n",
    "    test_dataset = dataset_val\n",
    "    # test_ids = [402,560, 50,  537, 390,\n",
    "    #             364, 169, 616, 341, 590,\n",
    "    #             499, 389,125, 370, 614,\n",
    "    #             600, 194, 8, 653, 559]\n",
    "#     test_ids = [602,194,560,390,402,537,625,8, 628,559,626,370,125,389,364,169,499,341,50]\n",
    "    test_ids = list(range(10))\n",
    "    inputs = torch.cat([test_dataset[idx]['points'].to(device).unsqueeze(0) for idx in test_ids])\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    print(inputs.shape) # fixme\n",
    "\n",
    "    shapedata_mean = torch.Tensor(shapedata.mean).to(device)\n",
    "    shapedata_std = torch.Tensor(shapedata.std).to(device)\n",
    "\n",
    "    z, outputs = optimize_to_get_result(model, loss_fn, args['nz'], device,\n",
    "                          inputs)\n",
    "    from pprint import pprint\n",
    "    pprint(z)\n",
    "\n",
    "    outputs = outputs[:,:-1]\n",
    "    inputs = inputs[:,:-1]\n",
    "\n",
    "    old_outputs = outputs\n",
    "    old_inputs = inputs\n",
    "\n",
    "    outputs = outputs * shapedata_std + shapedata_mean\n",
    "    inputs = inputs * shapedata_std + shapedata_mean\n",
    "\n",
    "    per_l2_loss = torch.sqrt(torch.sum((outputs - inputs)**2, dim=2))\n",
    "\n",
    "    for i in range(len(test_ids)):\n",
    "        print(test_ids[i], torch.mean(per_l2_loss[i]))\n",
    "\n",
    "    shapedata.save_meshes(os.path.join(worst_mesh_path, 'opt_input'),old_inputs.detach().cpu().numpy(),test_ids)\n",
    "    shapedata.save_meshes(os.path.join(worst_mesh_path, 'opt_output'),old_outputs.detach().cpu().numpy(),test_ids)\n",
    "\n",
    "work_optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=args['nz'])\n",
    "X = np.array([dataset_train[i]['points'].cpu().numpy() for i in range(len(dataset_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], -1)\n",
    "W = pca.fit_transform(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34533, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 34533)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array([dataset_val[i]['points'].cpu().numpy() for i in range(len(dataset_val))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11511, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = np.mean(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34533, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = X_val.reshape(X_val.shape[0], -1).T\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linalg.lstsq(W,X_val-X_mean.reshape(-1,1),rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_recon = W@x+X_mean.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34533, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapedata.save_meshes(os.path.join(worst_mesh_path,'pca'),pca_recon.T, list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapedata.save_meshes(os.path.join(worst_mesh_path,'val_input'),X_val.T,list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34533, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11510, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapedata.std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11510, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapedata.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val[:-3]\n",
    "pca_recon = pca_recon[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_denorm = X_val * shapedata.std.reshape(-1,1) + shapedata.mean.reshape(-1,1)\n",
    "pca_denorm = pca_recon * shapedata.std.reshape(-1,1) + shapedata.mean.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34530, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_denorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34530, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_denorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = (X_val_denorm-pca_denorm)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = residual.reshape(-1,3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = np.sqrt(np.sum(residual,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11510, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7689099535346031"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(residual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34530, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27528316"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.sqrt((pca_recon-X_val)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899289"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_recon[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.62963533"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_denorm[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558933"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_recon = pca_recon[:-3].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_recon = pca_recon.reshape(pca_recon.shape[0],-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11510, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34533, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11510, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_denorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057275042"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_val_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0565793"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pca_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27528813"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual = (X_val-pca_recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, when latent is 16, PCA's reconstrution error is 1.76mm, while autoencoder's recons error is 1.55mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.55mm doesn't need to optimize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
